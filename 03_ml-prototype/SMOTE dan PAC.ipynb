{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_path = r'/Users/piikn/ridho/dataset/processed'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "##import shap\n",
    "##import scikitplot as skplt\n",
    "##import eli5\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, average_precision_score\n",
    "##from catboost import CatBoostClassifier\n",
    "##from catboost import Pool\n",
    "##from eli5.sklearn import PermutationImportance\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "from collections import defaultdict\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import describe\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {\n",
    "    'dst_port': 'uint32',\n",
    "    'protocol': 'uint8',\n",
    "    'timestamp': 'object',\n",
    "    'flow_duration': 'int64',\n",
    "    'tot_fwd_pkts': 'uint32',\n",
    "    'tot_bwd_pkts': 'uint32',\n",
    "    'totlen_fwd_pkts': 'uint32',\n",
    "    'totlen_bwd_pkts': 'uint32',\n",
    "    'fwd_pkt_len_max': 'uint16',\n",
    "    'fwd_pkt_len_min': 'uint16',\n",
    "    'fwd_pkt_len_mean': 'float32',\n",
    "    'fwd_pkt_len_std': 'float32',\n",
    "    'bwd_pkt_len_max': 'uint16',\n",
    "    'bwd_pkt_len_min': 'uint16',\n",
    "    'bwd_pkt_len_mean': 'float32',\n",
    "    'bwd_pkt_len_std': 'float32',\n",
    "    'flow_byts_s': 'float64',\n",
    "    'flow_pkts_s': 'float64',\n",
    "    'flow_iat_mean': 'float32',\n",
    "    'flow_iat_std': 'float32',\n",
    "    'flow_iat_max': 'int64',\n",
    "    'flow_iat_min': 'int64',\n",
    "    'fwd_iat_tot': 'int64',\n",
    "    'fwd_iat_mean': 'float32',\n",
    "    'fwd_iat_std': 'float32',\n",
    "    'fwd_iat_max': 'int64',\n",
    "    'fwd_iat_min': 'int64',\n",
    "    'bwd_iat_tot': 'uint32',\n",
    "    'bwd_iat_mean': 'float32',\n",
    "    'bwd_iat_std': 'float32',\n",
    "    'bwd_iat_max': 'uint32',\n",
    "    'bwd_iat_min': 'uint32',\n",
    "    'fwd_psh_flags': 'uint8',\n",
    "    'bwd_psh_flags': 'uint8',\n",
    "    'fwd_urg_flags': 'uint8',\n",
    "    'bwd_urg_flags': 'uint8',\n",
    "    'fwd_header_len': 'uint32',\n",
    "    'bwd_header_len': 'uint32',\n",
    "    'fwd_pkts_s': 'float32',\n",
    "    'bwd_pkts_s': 'float32',\n",
    "    'pkt_len_min': 'uint16',\n",
    "    'pkt_len_max': 'uint16',\n",
    "    'pkt_len_mean': 'float32',\n",
    "    'pkt_len_std': 'float32',\n",
    "    'pkt_len_var': 'float32',\n",
    "    'fin_flag_cnt': 'uint8',\n",
    "    'syn_flag_cnt': 'uint8',\n",
    "    'rst_flag_cnt': 'uint8',\n",
    "    'psh_flag_cnt': 'uint8',\n",
    "    'ack_flag_cnt': 'uint8',\n",
    "    'urg_flag_cnt': 'uint8',\n",
    "    'cwe_flag_count': 'uint8',\n",
    "    'ece_flag_cnt': 'uint8',\n",
    "    'down_up_ratio': 'uint16',\n",
    "    'pkt_size_avg': 'float32',\n",
    "    'fwd_seg_size_avg': 'float32',\n",
    "    'bwd_seg_size_avg': 'float32',\n",
    "    'fwd_byts_b_avg': 'uint8',\n",
    "    'fwd_pkts_b_avg': 'uint8',\n",
    "    'fwd_blk_rate_avg': 'uint8',\n",
    "    'bwd_byts_b_avg': 'uint8',\n",
    "    'bwd_pkts_b_avg': 'uint8',\n",
    "    'bwd_blk_rate_avg': 'uint8',\n",
    "    'subflow_fwd_pkts': 'uint32',\n",
    "    'subflow_fwd_byts': 'uint32',\n",
    "    'subflow_bwd_pkts': 'uint32',\n",
    "    'subflow_bwd_byts': 'uint32',\n",
    "    'init_fwd_win_byts': 'int32',\n",
    "    'init_bwd_win_byts': 'int32',\n",
    "    'fwd_act_data_pkts': 'uint32',\n",
    "    'fwd_seg_size_min': 'uint8',\n",
    "    'active_mean': 'float32',\n",
    "    'active_std': 'float32',\n",
    "    'active_max': 'uint32',\n",
    "    'active_min': 'uint32',\n",
    "    'idle_mean': 'float32',\n",
    "    'idle_std': 'float32',\n",
    "    'idle_max': 'uint64',\n",
    "    'idle_min': 'uint64',\n",
    "    'label': 'category'\n",
    "}\n",
    "\n",
    "def replace_infinity_with_mean(df):\n",
    "    inf_columns = [c for c in df.columns if df[df[c] == np.inf][c].count() > 0]\n",
    "    for col in inf_columns:\n",
    "        df[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        mean = df[col].mean()\n",
    "        df[col].fillna(mean, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_negative_values_with_mean(df):\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.values\n",
    "    \n",
    "    columns = [c for c in numeric_cols if df[df[c] < 0][c].count() > 0]\n",
    "    for col in columns:\n",
    "        mask = df[col] < 0\n",
    "        df.loc[mask, col] = np.nan\n",
    "        mean = df[col].mean()\n",
    "        df[col].fillna(mean, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_dataset(files, dtypes, cols=None):\n",
    "    df = pd.concat((pd.read_csv(f, dtype=dtypes, usecols=cols) for f in files))\n",
    "    \n",
    "    df = replace_infinity_with_mean(df)\n",
    "    df = replace_negative_values_with_mean(df)\n",
    "        \n",
    "    df['label_cat'] = df.label.astype('category').cat.codes\n",
    "    df['label_is_attack'] = (df.label != 'Benign').astype('int')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data preparation\n",
    "\n",
    "csv_files = glob.glob(os.path.join(dataset_base_path, '*.csv'))\n",
    "\n",
    "df = load_dataset(csv_files, types)\n",
    "X = df.drop(columns=['label', 'label_cat', 'label_is_attack'])\n",
    "y = df[['label_is_attack', 'label_cat', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    bwd_blk_rate_avg\n",
       "5      bwd_byts_b_avg\n",
       "6      bwd_pkts_b_avg\n",
       "0       bwd_psh_flags\n",
       "1       bwd_urg_flags\n",
       "4    fwd_blk_rate_avg\n",
       "2      fwd_byts_b_avg\n",
       "3      fwd_pkts_b_avg\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## all features with zero amount of variation are removed as those features will not have any influence on the prediction \n",
    "## All features having a standard deviation of 0 are selected and will be dropped subsequently.\n",
    "## hasilnya adalah fitur2 yang memiliki nilai deviasi 0\n",
    "\n",
    "stats = X.describe()\n",
    "std = stats.loc['std']\n",
    "features_no_variance = std[std == 0.0].index\n",
    "pd.Series(features_no_variance).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perintah menghilangkan feature2 yang diatas\n",
    "X = X.drop(columns=features_no_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['timestamp', 'dst_port'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In order to train and evaluate different models a train/evaluation/test split is created with the ratios of 0.8/0.1/0.1\n",
    "def print_report(ds_type, cls, X_vals, y_true, y_predict, plot_pr=False, plot_roc=False):\n",
    "    print(f\"Classification Report ({ds_type}):\")\n",
    "    print(classification_report(y_true, y_predict))\n",
    "    print(f\"Avg Precision Score: {average_precision_score(y_true, y_predict, average='weighted')}\")\n",
    "    \n",
    "    if plot_roc:\n",
    "        print(f\"ROC AUC Score: {roc_auc_score(y_true, y_predict)}\")\n",
    "        skplt.metrics.plot_roc(y_true, cls.predict_proba(X_vals))\n",
    "        plt.show()\n",
    "        \n",
    "    if plot_pr:\n",
    "        \n",
    "        skplt.metrics.plot_precision_recall(y_true, cls.predict_proba(X_vals))\n",
    "        plt.show()\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the data\n",
    "\n",
    "X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.2, stratify=y.label_cat)\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_hold, y_hold, test_size=0.5, stratify=y_hold.label_cat)\n",
    "\n",
    "X_train_oh = pd.get_dummies(X_train, columns=['protocol'])\n",
    "X_eval_oh = pd.get_dummies(X_eval, columns=['protocol'])\n",
    "X_test_oh = pd.get_dummies(X_test, columns=['protocol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      13484708\n",
       "DDOS attack-HOIC              686012\n",
       "DDoS attacks-LOIC-HTTP        576191\n",
       "DoS attacks-Hulk              461912\n",
       "Bot                           286191\n",
       "FTP-BruteForce                193360\n",
       "SSH-Bruteforce                187589\n",
       "Infilteration                 161934\n",
       "DoS attacks-SlowHTTPTest      139890\n",
       "DoS attacks-GoldenEye          41508\n",
       "DoS attacks-Slowloris          10990\n",
       "DDOS attack-LOIC-UDP            1730\n",
       "Brute Force -Web                 611\n",
       "Brute Force -XSS                 230\n",
       "SQL Injection                     87\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      10787766\n",
       "DDOS attack-HOIC              548809\n",
       "DDoS attacks-LOIC-HTTP        460953\n",
       "DoS attacks-Hulk              369530\n",
       "Bot                           228953\n",
       "FTP-BruteForce                154688\n",
       "SSH-Bruteforce                150071\n",
       "Infilteration                 129547\n",
       "DoS attacks-SlowHTTPTest      111912\n",
       "DoS attacks-GoldenEye          33206\n",
       "DoS attacks-Slowloris           8792\n",
       "DDOS attack-LOIC-UDP            1384\n",
       "Brute Force -Web                 489\n",
       "Brute Force -XSS                 184\n",
       "SQL Injection                     70\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      1348471\n",
       "DDOS attack-HOIC              68601\n",
       "DDoS attacks-LOIC-HTTP        57619\n",
       "DoS attacks-Hulk              46191\n",
       "Bot                           28619\n",
       "FTP-BruteForce                19336\n",
       "SSH-Bruteforce                18759\n",
       "Infilteration                 16193\n",
       "DoS attacks-SlowHTTPTest      13989\n",
       "DoS attacks-GoldenEye          4151\n",
       "DoS attacks-Slowloris          1099\n",
       "DDOS attack-LOIC-UDP            173\n",
       "Brute Force -Web                 61\n",
       "Brute Force -XSS                 23\n",
       "SQL Injection                     9\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      1348471\n",
       "DDOS attack-HOIC              68602\n",
       "DDoS attacks-LOIC-HTTP        57619\n",
       "DoS attacks-Hulk              46191\n",
       "Bot                           28619\n",
       "FTP-BruteForce                19336\n",
       "SSH-Bruteforce                18759\n",
       "Infilteration                 16194\n",
       "DoS attacks-SlowHTTPTest      13989\n",
       "DoS attacks-GoldenEye          4151\n",
       "DoS attacks-Slowloris          1099\n",
       "DDOS attack-LOIC-UDP            173\n",
       "Brute Force -Web                 61\n",
       "Brute Force -XSS                 23\n",
       "SQL Injection                     8\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class occurences:\n",
      "0    10787766\n",
      "1     2198588\n",
      "Name: label_is_attack, dtype: int64\n",
      "Percentage of benign samples: 0.8307\n"
     ]
    }
   ],
   "source": [
    "## metric untuk mengukur banyaknya jumlah data anomaly /attack\n",
    "percentage_benign = len(y_train.label_is_attack[y_train.label_is_attack == 0]) / len(y_train.label_is_attack)\n",
    "\n",
    "print('Class occurences:')\n",
    "print(y_train.label_is_attack.value_counts())\n",
    "print('Percentage of benign samples: %.4f' % percentage_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      10787766\n",
       "DDOS attack-HOIC              548809\n",
       "DDoS attacks-LOIC-HTTP        460953\n",
       "DoS attacks-Hulk              369530\n",
       "Bot                           228953\n",
       "FTP-BruteForce                154688\n",
       "SSH-Bruteforce                150071\n",
       "Infilteration                 129547\n",
       "DoS attacks-SlowHTTPTest      111912\n",
       "DoS attacks-GoldenEye          33206\n",
       "DoS attacks-Slowloris           8792\n",
       "DDOS attack-LOIC-UDP            1384\n",
       "Brute Force -Web                 489\n",
       "Brute Force -XSS                 184\n",
       "SQL Injection                     70\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The distribution of classes shows that the dataset is highly imbalanced with class 0 - Benign contributing to ~83% of all the samples.\n",
    "## Synthetic Minority Oversampling is used to push the occurrences of those classes to 100000.\n",
    "\n",
    "cnts = y_train.label_cat.value_counts()\n",
    "sample_dict = {}\n",
    "\n",
    "for i in np.unique(y_train.label_cat):\n",
    "    sample_dict[i] = max(cnts[i], 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-02c0fade3442>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTENC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sBVCX\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     79\u001b[0m         )\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X_columns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\imblearn\\over_sampling\\_smote.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m         \u001b[0mX_continuous\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinuous_features_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 944\u001b[1;33m         \u001b[0mX_continuous\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_continuous\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    945\u001b[0m         X_minority = _safe_indexing(\n\u001b[0;32m    946\u001b[0m             \u001b[0mX_continuous\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mclass_minority\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sm = SMOTENC(sampling_strategy=sample_dict, categorical_features=[0], n_jobs=24)\n",
    "X_train_s, y_train_sBVCX= sm.fit_resample(X_train, y_train.label_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class occurrences:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9dd4fae7e10a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Class occurrences:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "print('Class occurrences:')\n",
    "Counter(y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_s = (y_train_s != 0).astype('int')\n",
    "print('Binary label occurrences:')\n",
    "Counter(y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction dengan PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=79) ## jumlah feature tersisa setelah dikurangi dst_port dan timestamp\n",
    "fit = pca.fit(X_train)\n",
    "# summarize components\n",
    "\n",
    "print(\"Explained Variance: %s\" % (fit.explained_variance_ratio_,))\n",
    "print(fit.components_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
